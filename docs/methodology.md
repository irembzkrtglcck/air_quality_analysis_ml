# ğŸ”¬ Metodoloji DokÃ¼mantasyonu

Bu belge, hava kalitesi analizi projesinde kullanÄ±lan tÃ¼m yÃ¶ntemlerin detaylÄ± aÃ§Ä±klamalarÄ±nÄ± iÃ§erir.

---

## ğŸ“š Ä°Ã§indekiler

1. [Veri Ã–n Ä°ÅŸleme](#1-veri-Ã¶n-iÅŸleme)
2. [Ã–zellik MÃ¼hendisliÄŸi](#2-Ã¶zellik-mÃ¼hendisliÄŸi)
3. [Boyut Ä°ndirgeme Teknikleri](#3-boyut-indirgeme-teknikleri)
4. [SÄ±nÄ±flandÄ±rma Modelleri](#4-sÄ±nÄ±flandÄ±rma-modelleri)
5. [KÃ¼meleme Analizi](#5-kÃ¼meleme-analizi)
6. [DeÄŸerlendirme Metrikleri](#6-deÄŸerlendirme-metrikleri)

---

## 1. Veri Ã–n Ä°ÅŸleme

### 1.1. Eksik DeÄŸer KontrolÃ¼

```python
# Eksik deÄŸer kontrolÃ¼
print(air_quality.isnull().sum())
```

**SonuÃ§:** Veri setinde eksik deÄŸer bulunmamaktadÄ±r.

### 1.2. Negatif DeÄŸer Temizleme

**Problem:** Fiziksel olarak negatif olamayan deÄŸiÅŸkenlerde negatif deÄŸerler tespit edildi.

| DeÄŸiÅŸken | Negatif SayÄ±sÄ± |
|----------|----------------|
| PM10 | 1 |
| SO2 | 30 |

**Ã‡Ã¶zÃ¼m:** Medyan imputation

```python
# Medyan ile doldurma
air_quality.loc[air_quality['PM10'] < 0, 'PM10'] = air_quality['PM10'].median()
air_quality.loc[air_quality['SO2'] < 0, 'SO2'] = air_quality['SO2'].median()
```

**Neden Medyan?**
- AykÄ±rÄ± deÄŸerlerden etkilenmez
- DaÄŸÄ±lÄ±mÄ± korur
- Ortalamaya gÃ¶re daha robust

### 1.3. Standardizasyon

**YÃ¶ntem:** StandardScaler (Z-score normalizasyonu)

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

**FormÃ¼l:**
```
z = (x - Î¼) / Ïƒ
```

**Neden StandardScaler?**
- Mesafe tabanlÄ± algoritmalar iÃ§in kritik (KNN, SVM)
- PCA iÃ§in gerekli
- FarklÄ± Ã¶lÃ§ekli deÄŸiÅŸkenleri aynÄ± dÃ¼zeye getirir

---

## 2. Ã–zellik MÃ¼hendisliÄŸi

### 2.1. Label Encoding (Hedef DeÄŸiÅŸken)

```python
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
y_encoded = le.fit_transform(y)

# EÅŸleÅŸmeler:
# Good â†’ 0
# Hazardous â†’ 1
# Moderate â†’ 2
# Poor â†’ 3
```

### 2.2. SÄ±nÄ±f DengesizliÄŸi - SMOTE

**Problem:** Dengesiz sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±

| SÄ±nÄ±f | SMOTE Ã–ncesi | SMOTE SonrasÄ± |
|-------|--------------|---------------|
| Good | 1,600 | 1,600 |
| Moderate | 1,200 | 1,600 |
| Poor | 800 | 1,600 |
| Hazardous | 400 | 1,600 |

**SMOTE AlgoritmasÄ±:**

```python
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
```

**NasÄ±l Ã‡alÄ±ÅŸÄ±r?**
1. AzÄ±nlÄ±k sÄ±nÄ±fÄ±ndan bir Ã¶rnek seÃ§
2. K-en yakÄ±n komÅŸularÄ±nÄ± bul
3. KomÅŸularla doÄŸrusal interpolasyon yap
4. Sentetik Ã¶rnek oluÅŸtur

**AvantajlarÄ±:**
- Overfitting riski dÃ¼ÅŸÃ¼k
- Test setine dokunmaz
- Hassas sÄ±nÄ±flarda performansÄ± artÄ±rÄ±r

---

## 3. Boyut Ä°ndirgeme Teknikleri

### 3.1. PCA (Principal Component Analysis)

**AmaÃ§:** VaryansÄ± maksimize eden yeni eksenler bul

**Uygulama:**
```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
```

**SonuÃ§lar:**
- Ä°lk 2 bileÅŸen: %70.69 varyans
- Ä°lk 3 bileÅŸen: %77.3 varyans

**AvantajlarÄ±:**
- Unsupervised (etiket gerektirmez)
- Ã‡oklu baÄŸlantÄ±yÄ± (multicollinearity) azaltÄ±r

**DezavantajlarÄ±:**
- Yorumlanabilirlik kaybÄ±
- SÄ±nÄ±f bilgisini kullanmaz

### 3.2. LDA (Linear Discriminant Analysis)

**AmaÃ§:** SÄ±nÄ±flar arasÄ± ayrÄ±mÄ± maksimize et

**FormÃ¼l:**
```
maximize: (between-class variance) / (within-class variance)
```

**Uygulama:**
```python
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA

lda = LDA(n_components=2)
X_lda = lda.fit_transform(X_scaled, y)
```

**KÄ±sÄ±t:** n_components â‰¤ (n_classes - 1)

**AvantajlarÄ±:**
- SÄ±nÄ±flandÄ±rma iÃ§in optimize edilmiÅŸ
- PCA'dan daha iyi sÄ±nÄ±f ayrÄ±mÄ±

**DezavantajlarÄ±:**
- Supervised (etiket gerektirir)
- DoÄŸrusallÄ±k varsayÄ±mÄ±

### 3.3. t-SNE (t-Distributed Stochastic Neighbor Embedding)

**AmaÃ§:** YÃ¼ksek boyutlu komÅŸuluklarÄ± dÃ¼ÅŸÃ¼k boyutta koru

**Uygulama:**
```python
from sklearn.manifold import TSNE

tsne = TSNE(n_components=2, perplexity=30, learning_rate='auto')
X_tsne = tsne.fit_transform(X_scaled)
```

**Parametreler:**
- **perplexity:** KomÅŸu sayÄ±sÄ± (5-50 arasÄ± Ã¶nerilir)
- **learning_rate:** Optimizasyon hÄ±zÄ±

**AvantajlarÄ±:**
- DoÄŸrusal olmayan iliÅŸkileri yakalar
- GÃ¶rselleÅŸtirmede mÃ¼kemmel

**DezavantajlarÄ±:**